{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "\n",
    "english_stops = []\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    \"\"\" Lowercases, takes out punct and stopwords and short strings \"\"\"\n",
    "    return [token.lower() for token in tokens if (token not in string.punctuation) and\n",
    "               \t(token.lower() not in english_stops) and len(token) > 2]\n",
    "\n",
    "def get_stopwords():\n",
    "    enc = 'utf-8'\n",
    "    with open('stopword_file.csv', 'r', encoding = enc) as f:\n",
    "        reader = csv.reader(f)\n",
    "        keywords = list(reader)\n",
    "    english_stops = [i[0] for i in keywords]\n",
    "    #print ( english_stops)\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "def get_cleanTokens(directory):\n",
    "    cleanTokens = []\n",
    "    for filename in os.listdir(directory):\n",
    "        text = get_text(\"KeywordDocs/\" + filename)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        cleanTokens.extend(clean_tokens(tokens))\n",
    "    return cleanTokens\n",
    "     \n",
    "def create_freqList(cleanTokens):\n",
    "    wordcount = {} \n",
    "    for tok in cleanTokens:\n",
    "        if tok not in wordcount:\n",
    "            wordcount[tok] = 1\n",
    "        else:\n",
    "            wordcount[tok] += 1\n",
    "        \n",
    "    sorted_wordCount = OrderedDict(sorted(wordcount.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    write_csv(sorted_wordCount)\n",
    "\n",
    "def write_csv(sorted_wordCount):\n",
    "    enc = 'utf-8'\n",
    "    if not os.path.isfile('Data/frequency.csv'):\n",
    "        with open('Data/frequency.csv', 'w', encoding = enc) as f:\n",
    "            columnTitleRow = \"Word, Count\\n\"\n",
    "            f.write(columnTitleRow)\n",
    "            for key,value in sorted_wordCount.items():\n",
    "                f.write(\"%s, %d\\n\"%(key,value))\n",
    "    else:\n",
    "        with open('Data/frequency.csv', 'a+', encoding = enc) as f:\n",
    "            for key,value in sorted_wordCount.items():\n",
    "                f.write(\"%s,\\n\"%(key,value))\n",
    "\n",
    "\n",
    "def get_text(filename):\n",
    "    fp = open(filename, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_stopwords()\n",
    "    clean_tokens = get_cleanTokens(\"KeywordDocs\")\n",
    "    create_freqList(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
